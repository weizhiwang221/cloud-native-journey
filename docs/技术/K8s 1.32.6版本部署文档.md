

### ğŸ¤–ä¸»æœºé…ç½®

| ä½œç”¨       | IPåœ°å€       | æ“ä½œç³»ç»Ÿ              | é…ç½®       | å…³é”®ç»„ä»¶                     |
| ---------- | ------------ | --------------------- | ---------- | ---------------------------- |
| k8s-master | 192.168.1.30 | Rocky Linux release 9 | 4C/4G/50GB | kube-apiserver, etcd,,docker |
| k8s-node1  | 192.168.1.31 | Rocky Linux release9  | 4C/4G/50GB | kubelet, kube-proxy,docker   |
| k8s-node2  | 192.168.1.32 | Rocky Linux release 9 | 4C/4G/50GB | kubelet, kube-proxy,docker   |
| k8s-node3  | 192.168.1.33 | Rocky Linux release 9 | 4C/4G/50GB | kubelet, kube-proxy,docker   |

### ğŸªªè®¾ç½®IP

```bash
æ–¹å¼ä¸€ï¼š
nmcli connection modify ens160 ipv4.addresses 192.168.1.30/24 ipv4.gateway 192.168.1.1 ipv4.method manual
nmcli connection modify ens160 ipv4.addresses 192.168.1.31/24 ipv4.gateway 192.168.1.1 ipv4.method manual
nmcli connection modify ens160 ipv4.addresses 192.168.1.32/24 ipv4.gateway 192.168.1.1 ipv4.method manual
nmcli connection modify ens160 ipv4.addresses 192.168.1.33/24 ipv4.gateway 192.168.1.1 ipv4.method manual

nmcli connection up ens160

æ–¹å¼äºŒï¼š
vi /etc/NetworkManager/system-connections/ens160.nmconnection
method=manual## åœ¨IPV4ä¸‹é¢ä¿®æ”¹å¦‚ä¸‹å†…å®¹
address1=192.168.0.5/24,192.168.0.1## ä¿®æ”¹IPï¼Œå­ç½‘æ©ç ï¼ˆ24æ˜¯å­ç½‘æ©ç çš„24ä½ï¼Œå¯¹åº”255.255.255.0ï¼‰ï¼Œ ç½‘å…³
dns=119.29.29.29;114.114.114.114## è®¾ç½®DNSæœåŠ¡
may-fail=false

é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
nmcli connection reload ens160.nmconnection


æ¿€æ´»é…ç½®æ–‡ä»¶
nmcli connection up ens160
```

### ğŸš€é…ç½®YUMæº

1. é…ç½®yumæº

```bash
ï¼ˆ1ï¼‰ç¡®è®¤æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯è¯»
sudo cat /etc/yum.repos.d/rocky.repo
å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–å†…å®¹ä¸ºç©ºï¼Œé‡æ–°åˆ›å»ºå®ƒã€‚

ï¼ˆ2ï¼‰é‡æ–°ä¸‹è½½æ­£ç¡®çš„é˜¿é‡Œäº‘æºæ–‡ä»¶
sudo rm -f /etc/yum.repos.d/rocky.repo  # åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœæœ‰ï¼‰
sudo curl -o /etc/yum.repos.d/rocky.repo https://mirrors.aliyun.com/rockylinux/rocky.repo?repo=rocky-9
ï¼ˆ3ï¼‰æ‰‹åŠ¨ç¼–è¾‘æ–‡ä»¶ï¼ˆå¦‚æœä¸‹è½½å¤±è´¥ï¼‰
sudo vi /etc/yum.repos.d/rocky.repo
ç²˜è´´ä»¥ä¸‹å†…å®¹ï¼ˆé˜¿é‡Œäº‘ Rocky Linux 9 é•œåƒæºï¼‰ï¼š
[baseos]
name=Rocky Linux $releasever - BaseOS - Aliyun
baseurl=https://mirrors.aliyun.com/rockylinux/$releasever/BaseOS/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial

[appstream]
name=Rocky Linux $releasever - AppStream - Aliyun
baseurl=https://mirrors.aliyun.com/rockylinux/$releasever/AppStream/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial

[extras]
name=Rocky Linux $releasever - Extras - Aliyun
baseurl=https://mirrors.aliyun.com/rockylinux/$releasever/extras/$basearch/os/
gpgcheck=1
enabled=1
gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rockyofficial


ï¼ˆ4ï¼‰ä¹Ÿå¯ä»¥ç›´æ¥æ›¿æ¢yumæºé‡Œçš„åœ°å€
sed -e 's|^mirrorlist=|#mirrorlist=|g' \
    -e 's|^#baseurl=http://dl.rockylinux.org/$contentdir|baseurl=https://mirrors.aliyun.com/rockylinux|g' \
    -i.bak \
    /etc/yum.repos.d/rocky*.repo
```


2. å¼ºåˆ¶æ›¿æ¢å˜é‡ä¸º Rocky Linux 9
ç¡®ä¿ $releasever å’Œ $basearch è¢«æ­£ç¡®è§£æï¼š

```bash
sudo sed -i 's/$releasever/9/g' /etc/yum.repos.d/rocky.repo
sudo sed -i 's/$basearch/x86_64/g' /etc/yum.repos.d/rocky.repo  # å¦‚æœæ˜¯ x86_64 æ¶æ„
```


3. å¯¼å…¥ GPG å¯†é’¥

  ```bash
sudo rpm --import https://mirrors.aliyun.com/rockylinux/RPM-GPG-KEY-rockyofficial
  ```

4. æ£€æŸ¥æ–‡ä»¶æƒé™å’Œæ ¼å¼
    ï¼ˆ1ï¼‰ç¡®ä¿æ–‡ä»¶æƒé™æ­£ç¡®
    
    ```bash
    sudo chmod 644 /etc/yum.repos.d/rocky.repo
    ```
    

ï¼ˆ2ï¼‰æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼ˆé¿å… UTF-8 BOM æˆ– Windows æ¢è¡Œç¬¦ï¼‰
    
    ```bash
    sudo dos2unix /etc/yum.repos.d/rocky.repo  # å¦‚æœæ˜¯ä» Windows å¤åˆ¶çš„æ–‡ä»¶
    ```
    
    æ¸…é™¤ç¼“å­˜å¹¶é‡æ–°åŠ è½½

  ```bash
sudo dnf clean all
sudo dnf makecache
  ```

6. éªŒè¯ä»“åº“æ˜¯å¦å¯ç”¨

  ```bash
sudo dnf repolist
æ­£å¸¸è¾“å‡ºåº”ç±»ä¼¼ï¼š
text
repo id                          repo name
baseos                           Rocky Linux 9 - BaseOS - Aliyun
appstream                        Rocky Linux 9 - AppStream - Aliyun
extras                           Rocky Linux 9 - Extras - Aliyun
  ```

åœ¨ Rocky Linux 9 ä¸­å¯ç”¨å¹¶å®‰è£… EPEL Repoã€‚

```sql
dnf install epel-release
```

 å¤‡ä»½(å¦‚æœ‰é…ç½®å…¶ä»–epelæº)å¹¶æ›¿æ¢ä¸ºå›½å†…é•œåƒ
æ³¨æ„æœ€åè¿™ä¸ªåº“ï¼Œé˜¿é‡Œäº‘æ²¡æœ‰å¯¹åº”çš„é•œåƒï¼Œä¸è¦ä¿®æ”¹å®ƒï¼Œå¦‚æœè¯¯æ”¹æ¢å¤åŸç‰ˆæºå³å¯

```cobol
cp /etc/yum.repos.d/epel.repo  /etc/yum.repos.d/epel.repo.backup 
cp /etc/yum.repos.d/epel-testing.repo  /etc/yum.repos.d/epel-testing.repo.backup
cp /etc/yum.repos.d/epel-cisco-openh264.repo  /etc/yum.repos.d/epel-cisco-openh264.repo.backup
```

å°† repo é…ç½®ä¸­çš„åœ°å€æ›¿æ¢ä¸ºé˜¿é‡Œäº‘é•œåƒç«™åœ°å€

æ‰§è¡Œä¸‹é¢è¯­å¥ï¼Œå®ƒä¼šæ›¿æ¢epel.repoã€eple-testing.repoä¸­çš„ç½‘å€ï¼Œä¸ä¼šä¿®æ”¹epel-cisco-openh264.repoï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚

```cobol
sed -e 's!^metalink=!#metalink=!g' \
    -e 's!^#baseurl=!baseurl=!g' \
    -e 's!https\?://download\.fedoraproject\.org/pub/epel!https://mirrors.aliyun.com/epel!g' \
    -e 's!https\?://download\.example/pub/epel!https://mirrors.aliyun.com/epel!g' \
    -i /etc/yum.repos.d/epel{,-testing}.repo
```

æ›´æ–°ä»“åº“ç¼“å­˜

```sql
dnf clean all 
dnf makecache   ---ç”Ÿæˆç¼“å­˜ï¼Œå®‰è£…è½¯ä»¶æ›´å¿«
```

æ¯å°æœºå™¨å•ç‹¬åš

```bash
hostnamectl set-hostname k8s-master
hostnamectl set-hostname k8s-node1
hostnamectl set-hostname k8s-node2
hostnamectl set-hostname k8s-node3
```

è®¾ç½®hosts

```bash
cat >> /etc/hosts << EOF
192.168.1.30 k8s-master
192.168.1.31 k8s-node1
192.168.1.32 k8s-node2
192.168.1.33 k8s-node3
EOF
```

é…ç½®å…å¯†ç™»å½•ï¼Œ**åªåœ¨k8s-masterä¸Šæ“ä½œ**

```cobol
[root@k8s-master ~]# ssh-keygen -f ~/.ssh/id_rsa -N '' -q
```

 æ‹·è´å¯†é’¥åˆ°å…¶ä»–3 å°èŠ‚ç‚¹

```cobol
[root@k8s-master ~]# ssh-copy-id k8s-node1
[root@k8s-master ~]# ssh-copy-id k8s-node2
[root@k8s-master ~]# ssh-copy-id k8s-node3
```

### ğŸ§±é˜²ç«å¢™å’ŒSELinux

```bash
# å…³é—­é˜²ç«å¢™
systemctl disable --now firewalld
# ç¦ç”¨SELinux
sed -i '/^SELINUX=/ c SELINUX=disabled' /etc/selinux/config
# é‡å¯ç”Ÿæ•ˆæ‰€ä»¥ä¸´æ—¶è®¾ç½®ä¸ºå®½å®¹æ¨¡å¼
setenforce 0
```

### â±ï¸æ—¶é—´åŒæ­¥é…ç½®

```bash
# å®‰è£…æ—¶é—´æœåŠ¡å™¨è½¯ä»¶åŒ…
dnf install -y chrony
# ä¿®æ”¹åŒæ­¥æœåŠ¡å™¨
sed -i '/^pool/ c pool ntp1.aliyun.com  iburst' /etc/chrony.conf
systemctl restart chronyd
systemctl enable chronyd
chronyc sources
```

### ğŸ›é…ç½®å†…æ ¸è½¬å‘åŠç½‘æ¡¥è¿‡æ»¤

```bash
# æ·»åŠ ç½‘æ¡¥è¿‡æ»¤åŠå†…æ ¸è½¬å‘é…ç½®æ–‡ä»¶
cat > /etc/sysctl.d/k8s.conf << EOF
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
vm.swappiness = 0
EOF

# åŠ è½½br_netfilteræ¨¡å—
modprobe br_netfilter
```


ä½¿ç”¨æ–°æ·»åŠ é…ç½®æ–‡ä»¶ç”Ÿæ•ˆ

```bash
sysctl -p /etc/sysctl.d/k8s.conf
```

### ğŸ“´å…³é—­swap

æŸ¥çœ‹äº¤æ¢åˆ†åŒºæƒ…å†µ

```bash
# ä¸´æ—¶å…³é—­
swapoff -a
# æ°¸è¿œå…³é—­swapåˆ†åŒº
sed -i 's/.*swap.*/#&/' /etc/fstab
```

### ğŸ“„å¯ç”¨ipvs

```bash
cat >> /etc/modules-load.d/ipvs.conf << EOF
br_netfilter
ip_conntrack
ip_vs
ip_vs_lc
ip_vs_wlc
ip_vs_rr
ip_vs_wrr
ip_vs_lblc
ip_vs_lblcr
ip_vs_dh
ip_vs_sh
ip_vs_fo
ip_vs_nq
ip_vs_sed
ip_vs_ftp
ip_vs_sh
nf_conntrack
ip_tables
ip_set
xt_set
ipt_set
ipt_rpfilter
ipt_REJECT
ipip
EOF


# å®‰è£…ä¾èµ–
dnf install ipvsadm ipset sysstat conntrack libseccomp -y
```

 é‡å¯æœåŠ¡

```bash
systemctl restart systemd-modules-load.service
```

æŸ¥çœ‹æ¨¡å—å†…å®¹

```bash
lsmod | grep -e ip_vs -e nf_conntrack
```

### ğŸ“ƒå¥æŸ„æ•°æœ€å¤§

```bash
# è®¾ç½®ä¸ºæœ€å¤§
ulimit -SHn 65535

cat >> /etc/security/limits.conf <<EOF
* soft nofile 655360
* hard nofile 131072
* soft nproc 655350
* hard nproc 655350
* seft memlock unlimited
* hard memlock unlimitedd
EOF

      
# æŸ¥çœ‹ä¿®æ”¹ç»“æœ
ulimit -a
```

### ğŸ—ƒï¸ç³»ç»Ÿä¼˜åŒ–

```bash
cat > /etc/sysctl.d/k8s_better.conf << EOF
net.bridge.bridge-nf-call-iptables=1
net.bridge.bridge-nf-call-ip6tables=1
net.ipv4.ip_forward=1
vm.swappiness=0
vm.overcommit_memory=1
vm.panic_on_oom=0
fs.inotify.max_user_instances=8192
fs.inotify.max_user_watches=1048576
fs.file-max=52706963
fs.nr_open=52706963
net.ipv6.conf.all.disable_ipv6=1
net.netfilter.nf_conntrack_max=2310720
EOF


modprobe br_netfilter
lsmod |grep conntrack
modprobe ip_conntrack
sysctl -p /etc/sysctl.d/k8s_better.conf
```

###  ğŸ‹å®‰è£…docker

```bash
# Step 1: å®‰è£…ä¾èµ–
yum install -y yum-utils device-mapper-persistent-data lvm2
 
# Step 2: æ·»åŠ è½¯ä»¶æºä¿¡æ¯
yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/rhel/docker-ce.repo

# Step 3: å®‰è£…Docker-CE
yum -y install docker-ce
 
# docker -v
Docker version 27.5.1, build 9f9e405
 
# è®¾ç½®å›½å†…é•œåƒåŠ é€Ÿ
mkdir -p /etc/docker/ 
cat  >> /etc/docker/daemon.json << EOF
{
   "registry-mirrors":["https://p3kgr6db.mirror.aliyuncs.com",
   "https://docker.m.daocloud.io",
   "https://your_id.mirror.aliyuncs.com",
   "https://docker.nju.edu.cn/",
    "https://docker.anyhub.us.kg",
    "https://dockerhub.jobcher.com",
    "https://dockerhub.icu",
    "https://docker.ckyl.me",
       "https://cr.console.aliyun.com"
   ],
"exec-opts": ["native.cgroupdriver=systemd"]
}
EOF
 
 
# è®¾ç½®dockerå¼€æœºå¯åŠ¨å¹¶å¯åŠ¨
systemctl enable --now docker

# æŸ¥çœ‹dockerç‰ˆæœ¬
docker version
```

### å®‰è£…cri-dockerd

ä¸‹è½½åœ°å€ï¼š[Releases Â· Mirantis/cri-dockerd (github.com)](https://links.jianshu.com/go?to=https%3A%2F%2Flink.zhihu.com%2F%3Ftarget%3Dhttps%3A%2F%2Fgithub.com%2FMirantis%2Fcri-dockerd%2Freleases)ã€‚

https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.16/cri-dockerd-0.3.16-3.fc35.x86_64.rpm

#### å®‰è£…cri-docker

```bash
# ä¸‹è½½rpmåŒ…
wget -c https://github.com/Mirantis/cri-dockerd/releases/download/v0.3.16/cri-dockerd-0.3.16-3.fc35.x86_64.rpm
wget -c https://rpmfind.net/linux/almalinux/8.10/BaseOS/x86_64/os/Packages/libcgroup-0.41-19.el8.x86_64.rpm

# å®‰è£…rpmåŒ…
yum install libcgroup-0.41-19.el8.x86_64.rpm
yum install cri-dockerd-0.3.16-3.fc35.x86_64.rpm
```

#### è®¾ç½®cri-dockeræœåŠ¡å¼€æœºè‡ªå¯

```bash
systemctl enable cri-docker
```

#### cri-dockeè®¾ç½®å›½å†…é•œåƒåŠ é€Ÿ

```bash

# ç¼–è¾‘serviceæ–‡ä»¶
vim /usr/lib/systemd/system/cri-docker.serviceæ–‡ä»¶
ä¿®æ”¹ç¬¬10è¡Œå†…å®¹
------------------
ExecStart=/usr/bin/cri-dockerd  --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.9  --container-runtime-endpoint  fd://
-----------------------------------
 
# é‡å¯Dockerç»„ä»¶
systemctl daemon-reload && systemctl restart docker cri-docker.socket cri-docker 

# æ£€æŸ¥Dockerç»„ä»¶çŠ¶æ€
systemctl status docker cir-docker.socket cri-docker
```

### â˜¸ï¸K8Sè½¯ä»¶å®‰è£…

```bash
# 1ã€é…ç½®kubernetesæº
cat <<EOF | tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/
enabled=1
gpgcheck=1
gpgkey=https://mirrors.aliyun.com/kubernetes-new/core/stable/v1.32/rpm/repodata/repomd.xml.key
EOF
 
# 2ã€æŸ¥çœ‹æ‰€æœ‰å¯ç”¨çš„ç‰ˆæœ¬
yum list kubelet --showduplicates | sort -r |grep 1.32
 
# 3ã€å®‰è£…kubeletã€kubeadmã€kubectlã€kubernetes-cni
yum install -y kubelet kubeadm kubectl kubernetes-cni
 
# 4ã€é…ç½®cgroup
ä¸ºäº†å®ç°dockerä½¿ç”¨çš„cgroupdriverä¸kubeletä½¿ç”¨çš„cgroupçš„ä¸€è‡´æ€§ï¼Œå»ºè®®ä¿®æ”¹å¦‚ä¸‹æ–‡ä»¶å†…å®¹ã€‚
vim /etc/sysconfig/kubelet  [3å°å…¨éƒ¨è®¾ç½®ä¸‹]
---------------------
KUBELET_EXTRA_ARGS="--cgroup-driver=systemd"
---------------------

# 5ã€è®¾ç½®kubeletä¸ºå¼€æœºè‡ªå¯åŠ¨å³å¯ï¼Œç”±äºæ²¡æœ‰ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼Œé›†ç¾¤åˆå§‹åŒ–åè‡ªåŠ¨å¯åŠ¨
systemctl enable kubelet
```

### K8Sé›†ç¾¤åˆå§‹åŒ–

```bash
# åªåœ¨k8s-masterèŠ‚ç‚¹ä¸Šæ“ä½œ
[root@localhost ~]#  kubeadm config print init-defaults > kubeadm-init.yaml

# ç¼–è¾‘kubeadm-init.yamlä¿®æ”¹å¦‚ä¸‹é…ç½®ï¼š
- advertiseAddressï¼šä¸ºæ§åˆ¶å¹³é¢åœ°å€ï¼Œï¼ˆMasterä¸»æœºIPï¼‰
	advertiseAddress: 1.2.3.4
ä¿®æ”¹ä¸º advertiseAddress: 192.168.1.30

- criSocketï¼šä¸º containerd çš„socket æ–‡ä»¶åœ°å€
	criSocket: unix:///var/run/containerd/containerd.sock
ä¿®æ”¹ä¸º criSocket: unix:///var/run/cri-dockerd.sock

- name: node ä¿®æ”¹nodeä¸ºk8s-master
	name: node
ä¿®æ”¹ä¸º name: k8s-master
 
- imageRepositoryï¼šé˜¿é‡Œäº‘é•œåƒä»£ç†åœ°å€ï¼Œå¦åˆ™æ‹‰å–é•œåƒä¼šå¤±è´¥
	imageRepository: registry.k8s.io
ä¿®æ”¹ä¸ºï¼šimageRepository: registry.aliyuncs.com/google_containers

- kubernetesVersionï¼šä¸ºk8sç‰ˆæœ¬
	kubernetesVersion: 1.32.0
ä¿®æ”¹ä¸ºï¼škubernetesVersion: 1.32.6


# æ–‡ä»¶æœ«å°¾å¢åŠ å¯ç”¨ipvsåŠŸèƒ½
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
mode: ipvs



# æ ¹æ®é…ç½®æ–‡ä»¶å¯åŠ¨kubeadmåˆå§‹åŒ–k8s
$ kubeadm init --config=kubeadm-init.yaml --upload-certs --v=6
è¾“å‡ºç»“æœï¼š
Your Kubernetes control-plane has initialized successfully!
 
To start using your cluster, you need to run the following as a regular user:
 
  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config
 
Alternatively, if you are the root user, you can run:
 
  export KUBECONFIG=/etc/kubernetes/admin.conf
 
You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/
 
Then you can join any number of worker nodes by running the following on each as root:
 
kubeadm join 192.168.1.30:6443 --token abcdef.0123456789abcdef \
	--discovery-token-ca-cert-hash sha256:9d25c16abfec6ff6832ed2260c6c998d3fa6fedef61529d88520d3038bdbdde5
```

### K8Sé›†ç¾¤å·¥ä½œèŠ‚ç‚¹åŠ å…¥

```bash
# æ³¨æ„ï¼šåŠ å…¥é›†ç¾¤æ—¶éœ€è¦æ·»åŠ  --cri-socket unix:///var/run/cri-dockerd.sock
kubeadm join 192.168.1.30:6443 --token abcdef.0123456789abcdef \
	--discovery-token-ca-cert-hash sha256:9d25c16abfec6ff6832ed2260c6c998d3fa6fedef61529d88520d3038bdbdde5 \
        --cri-socket unix:///var/run/cri-dockerd.sock
```

### K8Sé›†ç¾¤ç½‘ç»œæ’ä»¶ä½¿ç”¨

```bash
# ä¸‹è½½calicoèµ„æºæ¸…å•
wget  --no-check-certificate   https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/calico.yaml

# ä¿®æ”¹calicoæ–‡ä»¶
vim calico.yaml
- name: CALICO_IPV4POOL_CIDR
  value: "10.244.0.0/16"
  
# å¯ä»¥å°†é•œåƒæå‰æ‹‰å–ä¸‹æ¥,å¦‚æœå®˜ç½‘ä»“åº“ä¸å¯è¾¾ï¼Œå¯ä»¥å°è¯•æ‰‹åŠ¨ä»quay.ioä¸‹è½½é•œåƒï¼Œquay.ioæ˜¯ä¸€ä¸ªå…¬å…±é•œåƒä»“åº“ã€‚
docker pull calico/cni:v3.28.0
docker pull calico/node:v3.28.0
docker pull calico/kube-controllers:v3.28.0

# åº”ç”¨calicoèµ„æºæ¸…å•
kubectl apply -f calico.yaml
```

**Kubectlå‘½ä»¤è‡ªåŠ¨è¡¥å…¨**

```bash
yum -y install bash-completion
source /usr/share/bash-completion/bash_completion
source <(kubectl completion bash)
echo "source <(kubectl completion bash)" >> ~/.bashrc
```

### å®‰è£…helm v3.16.3

```bash
wget https://get.helm.sh/helm-v3.16.3-linux-amd64.tar.gz
tar xf helm-v3.16.3-linux-amd64.tar.gz
cd linux-amd64/
mv helm /usr/local/bin
helm version
```

### éƒ¨ç½²åŠ¨æ€scå­˜å‚¨

```bash
# k8s-masterèŠ‚ç‚¹ä¸Šæ‰§è¡Œ
yum -y install nfs-utils
echo "/nfs/data/ *(insecure,rw,sync,no_root_squash)" > /etc/exports
mkdir -p /nfs/data/
chmod 777 -R /nfs/data/
systemctl enable rpcbind
systemctl enable nfs-server
systemctl start rpcbind
systemctl start nfs-server
exportfs  -v
```

åˆ›å»ºnfs-provisioner

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner  # saåå­—ï¼Œnfs-provisioner-deployé‡Œçš„è¦å¯¹åº”
  namespace: kube-system  # å‘½åç©ºé—´
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1  # åˆ›å»ºé›†ç¾¤è§„åˆ™
metadata:
  name: nfs-client-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
kind: ClusterRoleBinding   # å°†æœåŠ¡è®¤è¯ç”¨æˆ·ä¸é›†ç¾¤è§„åˆ™è¿›è¡Œç»‘å®š
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-nfs-client-provisioner
subjects:
  - kind: ServiceAccount   # ç±»å‹ä¸ºsa
    name: nfs-client-provisioner   # saçš„åå­—ä¸€è‡´
    namespace: kube-system  # å’Œnfs provisionerå®‰è£…çš„namespaceä¸€è‡´
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: kube-system # å’Œnfs provisionerå®‰è£…çš„namespaceä¸€è‡´
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: kube-system  # å’Œnfs provisionerå®‰è£…çš„namespaceä¸€è‡´
subjects:
  - kind: ServiceAccount  # ç±»å‹ä¸ºsa
    name: nfs-client-provisioner  # saçš„åå­—ä¸€è‡´
    namespace: kube-system # å’Œnfs provisionerå®‰è£…çš„namespaceä¸€è‡´
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  labels:
    app: nfs-client-provisioner
  namespace: kube-system  # éƒ¨ç½²åœ¨æŒ‡å®šnsä¸‹
spec:
  replicas: 1   # å‰¯æœ¬æ•°ï¼Œå»ºè®®ä¸ºå¥‡æ•°[1ï¼Œ3ï¼Œ5ï¼Œ7ï¼Œ9]
  strategy:
    type: Recreate   # ä½¿ç”¨é‡å»ºçš„å‡çº§ç­–ç•¥
  selector:
    matchLabels:
      app: nfs-client-provisioner
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner  # saåå­—ï¼Œè¿™ä¸ªæ˜¯åœ¨nfs-rbac.yamlé‡Œå®šä¹‰
      containers:
        - name: nfs-client-provisioner  # å®¹å™¨åå­—
          image: k8s.m.daocloud.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2  # é•œåƒåœ°å€ï¼Œè¿™é‡Œé‡‡ç”¨ç§æœ‰ä»“åº“ã€‚
          volumeMounts:
            - name: nfs-client-root
              mountPath: /persistentvolumes  # æŒ‡å®šå®¹å™¨å†…æŒ‚è½½çš„ç›®å½•
          env:
            - name: PROVISIONER_NAME  # å®¹å™¨å†…çš„å˜é‡ç”¨äºæŒ‡å®šæä¾›å­˜å‚¨çš„åç§°
              value: nfsnas     # nfs-provisionerçš„åç§°ï¼Œä»¥åè®¾ç½®çš„storage classè¦å’Œè¿™ä¸ªä¿æŒä¸€è‡´
            - name: NFS_SERVER      # å®¹å™¨å†…çš„å˜é‡æŒ‡å®šnfsæœåŠ¡å™¨å¯¹åº”çš„ç›®å½•
              value: 192.168.1.254  # NFSæœåŠ¡å™¨çš„åœ°å€
            - name: NFS_PATH           # å®¹å™¨å†…çš„å˜é‡æŒ‡å®šnfsæœåŠ¡å™¨å¯¹åº”çš„ç›®å½•
              value: /volume1/æœåŠ¡/K8s-NFS   # NFSæœåŠ¡çš„æŒ‚è½½ç›®å½•ï¼Œå¦‚æœé‡‡ç”¨è¿™ä¸ªnfsåŠ¨æ€ç”³è¯·PV,æ‰€åˆ›å»ºçš„æ–‡ä»¶åœ¨è¿™ä¸ªç›®å½•é‡Œï¼Œä¸€å®šè¦ç»™æƒé™ï¼Œç›´æ¥777ã€‚
      volumes:
        - name: nfs-client-root  # èµ‹å€¼å·åå­—
          nfs:
            server: 192.168.1.254  # NFSæœåŠ¡å™¨çš„åœ°å€
            path: /volume1/æœåŠ¡/K8s-NFS   # NFSæœåŠ¡çš„æŒ‚è½½ç›®å½•ï¼Œä¸€å®šè¦ç»™æƒé™ï¼Œç›´æ¥777ï¼Œä¸æœå°±æ˜¯å¹²
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfsnas
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"  # è®¾ä¸ºé»˜è®¤å­˜å‚¨ç±»
provisioner: nfsnas  # å¿…é¡»ä¸ Deployment ä¸­ PROVISIONER_NAME ä¸€è‡´
parameters:
  archiveOnDelete: "false"   # "true" è¡¨ç¤ºåˆ é™¤ PVC æ—¶å½’æ¡£æ•°æ®ï¼ˆé‡å‘½åç›®å½•ï¼‰
```







